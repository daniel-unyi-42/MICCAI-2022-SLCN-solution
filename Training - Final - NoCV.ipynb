{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beed1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mlp import MLP\n",
    "from train_test import train_model, test_model\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac407ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, img_dir, train, parity, warp, device):\n",
    "        if train:\n",
    "            self.ids = np.load('train.npy', allow_pickle=True)[:, 0]\n",
    "        else:\n",
    "            self.ids = np.load('validation.npy', allow_pickle=True)[:, 0]\n",
    "        self.df = pd.read_csv(\"dHCP_gDL_demographic_data.csv\")\n",
    "        self.df.insert(0, \"ID\", \"sub-\" + self.df[\"Subject ID \"] + \"_\" + \"ses-\" + self.df[\"Session ID\"].apply(str))\n",
    "        self.df.drop(\"Subject ID \", axis=1, inplace=True)\n",
    "        self.df.drop(\"Session ID\", axis=1, inplace=True)\n",
    "        self.mirror_index = np.load('mirror_index.npy') # mirrors the right hemisphere\n",
    "        self.train = train\n",
    "        self.img_dir = img_dir\n",
    "        self.parity = parity\n",
    "        self.warp = warp\n",
    "        self.mean = np.load('means_template.npy') # native for the other dataset\n",
    "        self.std = np.load('stds_template.npy') # native for the other dataset\n",
    "        self.neigh_orders = np.load('neigh_orders.npy')\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 2 * len(self.ids) if self.parity == 'both' else len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _id = self.ids[idx // 2] if self.parity == 'both' else self.ids[idx]\n",
    "        y = np.array([self.df.loc[self.df['ID'] == _id, 'GA at birth (weeks)'].item(),\n",
    "                      self.df.loc[self.df['ID'] == _id, 'PMA at scan (weeks)'].item(),\n",
    "                      self.df.loc[self.df['ID'] == _id, 'Birthweight (kg)'].item()])\n",
    "        parity_string = '_'\n",
    "        if self.parity == 'both':\n",
    "            if idx % 2 == 0:\n",
    "                parity_string += 'L'\n",
    "            else:\n",
    "                parity_string += 'R'\n",
    "        elif self.parity == 'left':\n",
    "            parity_string += 'L'\n",
    "        elif self.parity == 'right':\n",
    "            parity_string += 'R'\n",
    "        if self.warp:\n",
    "            parity_string += '_W%d' % (random.randint(1, 100))\n",
    "        img = nib.load(self.img_dir + _id + parity_string + '.shape.gii')\n",
    "        x = np.stack(img.agg_data(), axis=1)\n",
    "        x = x[self.neigh_orders].reshape([x.shape[0], 28])\n",
    "        if parity_string == '_R':\n",
    "            x = x[self.mirror_index]\n",
    "        x = (x - self.mean) / self.std\n",
    "        return torch.from_numpy(x).to(torch.float32).to(self.device), torch.from_numpy(y).to(torch.float32).to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bbf6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/regression_template_space_features_warped/' # native for the other dataset\n",
    "parity = 'both' # hemisphere choice: 'both', 'left', 'right'\n",
    "warp = False\n",
    "batch_size = 32\n",
    "breakpoint = 1000\n",
    "patience = 100 # for early stopping\n",
    "lr = 0.001\n",
    "#weight_decay = 0.01\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "# seed = 123\n",
    "\n",
    "# torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed(seed)\n",
    "\n",
    "# np.random.seed(seed)\n",
    "\n",
    "train_dataset = MyDataset(path, train=True, parity=parity, warp=warp, device=device)\n",
    "val_dataset = MyDataset(path, train=False, parity=parity, warp=False, device=device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f133253",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01def1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(28, [28, 28, 28, 28], 3, device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "print(model)\n",
    "print('Number of parameters: ', sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb09405d",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = []\n",
    "tr_losses = []\n",
    "# train with Adam\n",
    "best_val_index = -1\n",
    "p_counter = 0\n",
    "for epoch in range(1000):\n",
    "    train_loss = train_model(train_loader, model, optimizer)\n",
    "    val_loss = test_model(val_loader, model)\n",
    "    val_loss = val_loss.cpu().detach().numpy()\n",
    "    new_min = \" \"\n",
    "    if epoch > 0:\n",
    "        if val_losses[best_val_index] > val_loss:\n",
    "            new_min = \"*\"\n",
    "            best_val_index = epoch\n",
    "            torch.save(model.state_dict(), 'MLP_template.pt')\n",
    "            p_counter=0\n",
    "        else:\n",
    "            p_counter+=1\n",
    "        # max epoch is reached\n",
    "        if epoch - best_val_index > breakpoint:\n",
    "            print (\"Max epoch is reached\")\n",
    "            break\n",
    "        # early stopping is called\n",
    "        if p_counter > patience:\n",
    "            print (\"Early stopping, best val loss and index:\")\n",
    "            print(val_losses[best_val_index], best_val_index)\n",
    "            break\n",
    "    tr_losses.append(train_loss.cpu().detach().numpy())\n",
    "    val_losses.append(val_loss)\n",
    "    print(new_min, \"Epoch: %d, train loss: %1.3f, val loss: %1.3f\" % (epoch, train_loss, val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7748e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(tr_losses, 'g')\n",
    "plt.plot(val_losses, 'b')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
